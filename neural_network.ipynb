{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e330e82",
   "metadata": {},
   "source": [
    "# Neural Network from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ce8c952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Lambda\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6550d035",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3039274251.py, line 40)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[31m    \u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "class Network:\n",
    "    \"\"\"\n",
    "    Basic Neural Network, totally unoptimized\n",
    "    Uses Stochastic Gradient Descent as the optimizer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sizes: list[int]):\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "\n",
    "        # Where x is the size of the previous layer and y the size of the next layer\n",
    "        self.w = [\n",
    "            np.random.randn(y, x) for x, y in zip(self.sizes[:-1], self.sizes[1:])\n",
    "        ]\n",
    "        self.b = [np.random.randn(y, 1) for y in self.sizes[1:]]\n",
    "\n",
    "    def sigmoid(self, z: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Sigmoid Activation Function\"\"\"\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "    def forward(self, x: np.ndarray):\n",
    "        \"\"\"Forward Pass through the Network\"\"\"\n",
    "        for w, b in zip(self.w, self.b):\n",
    "            z = np.matmul(w, x) + b\n",
    "            x = self.sigmoid(z)\n",
    "        return x\n",
    "\n",
    "    def evaluate(self, test_data: Dataset):\n",
    "        \"\"\"\n",
    "        Nr of correctly classified test-samples\n",
    "        \"\"\"\n",
    "        test_results = [(np.argmax(self.forward(x)), y) for x, y in test_data]\n",
    "        return sum(int(x == y) for x, y in test_results)\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"Backpropagation\"\"\"\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        train_data: Dataset,\n",
    "        epochs: int = 20,\n",
    "        batch_size: int = 30,\n",
    "        lr: float = 0.01,\n",
    "        test_data: Optional[Dataset] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Training using Stochastic Gradient Descent.\n",
    "\n",
    "        If test_data is passed, then the network is evaluated on the test_data after each epoch\n",
    "        \"\"\"\n",
    "        if not train_data:\n",
    "            raise ValueError(\"train_data can not be none\")\n",
    "        n_train = len(train_data)\n",
    "        n_test = len(test_data) if test_data else None\n",
    "\n",
    "        test_results = []\n",
    "        for epoch in range(epochs):\n",
    "            batch = [\n",
    "                train_data[idx]\n",
    "                for idx in np.random.randint(low=0, high=n_train, size=batch_size)\n",
    "            ]\n",
    "\n",
    "            for x, y in batch:\n",
    "                y_pred = self.forward(x)\n",
    "\n",
    "            if test_data:\n",
    "                \"\"\"Compute the cost on the test set\"\"\"\n",
    "                test_result = self.evaluate(test_data)\n",
    "                test_results.append(test_result)\n",
    "                print(\n",
    "                    f\"Epoch: {epoch} / {epochs},\\t Nr of correctly classified samples: {test_result}/{n_test}\\t accuracy: {test_result / n_test:.5f}\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cc90eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    target_transform=Lambda(lambda y: F.one_hot(torch.tensor(y), num_classes=10)),\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    target_transform=Lambda(lambda y: F.one_hot(torch.tensor(y), num_classes=10)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982900a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e21d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network([784, 20, 10, 10])\n",
    "net.train(train_data, epochs=20, batch_size=30, lr=0.01, test_data=test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc17cf",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39204bfa",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc142fa6",
   "metadata": {},
   "source": [
    "Network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-network-from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
