{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e330e82",
   "metadata": {},
   "source": [
    "# Neural Network from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ce8c952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Lambda\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6550d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "class Network:\n",
    "    \"\"\"\n",
    "    Basic Neural Network, totally unoptimized\n",
    "    Uses Stochastic Gradient Descent as the optimizer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sizes: list[int]):\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "\n",
    "        # Where x is the size of the previous layer and y the size of the next layer\n",
    "        self.w = [\n",
    "            np.random.randn(y, x) for x, y in zip(self.sizes[:-1], self.sizes[1:])\n",
    "        ]\n",
    "        self.b = [np.random.randn(y, 1) for y in self.sizes[1:]]\n",
    "\n",
    "    def sigmoid(self, z: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Sigmoid Activation Function\"\"\"\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "    def forward(self, x: np.ndarray):\n",
    "        \"\"\"Forward Pass through the Network\"\"\"\n",
    "        for w, b in zip(self.w, self.b):\n",
    "            z = np.matmul(w, x) + b\n",
    "            x = self.sigmoid(z)\n",
    "        return x\n",
    "\n",
    "    def evaluate(self, test_data: Dataset):\n",
    "        \"\"\"\n",
    "        Nr of correctly classified test-samples\n",
    "        \"\"\"\n",
    "        test_results = [(np.argmax(self.forward(x)), y) for x, y in test_data]\n",
    "        return sum(int(x == y) for x, y in test_results)\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"Backpropagation\"\"\"\n",
    "        raise NotImplementedError(\"shit is not implemented yet\")\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        train_data: Dataset,\n",
    "        epochs: int = 20,\n",
    "        batch_size: int = 30,\n",
    "        lr: float = 0.01,\n",
    "        test_data: Optional[Dataset] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Training using Stochastic Gradient Descent.\n",
    "\n",
    "        If test_data is passed, then the network is evaluated on the test_data after each epoch\n",
    "        \"\"\"\n",
    "        if not train_data:\n",
    "            raise ValueError(\"train_data can not be none\")\n",
    "        n_train = len(train_data)\n",
    "        n_test = len(test_data) if test_data else None\n",
    "        n_batches = n_train // batch_size\n",
    "\n",
    "        test_results = []\n",
    "        for epoch in range(epochs):\n",
    "            for step in range(n_batches):\n",
    "                batch = [\n",
    "                    train_data[idx]\n",
    "                    for idx in np.random.randint(low=0, high=n_train, size=batch_size)\n",
    "                ]\n",
    "                self.minibatch_update(batch, lr)\n",
    "\n",
    "            # for x, y in batch:\n",
    "            #     y_pred = self.forward(x)\n",
    "\n",
    "            if test_data:\n",
    "                \"\"\"Compute the cost on the test set\"\"\"\n",
    "                test_result = self.evaluate(test_data)\n",
    "                test_results.append(test_result)\n",
    "                print(\n",
    "                    f\"Epoch: {epoch} / {epochs},\\t Nr of correctly classified samples: {test_result}/{n_test}\\t accuracy: {test_result / n_test:.5f}\"\n",
    "                )\n",
    "\n",
    "    def minibatch_update(\n",
    "        self, batch: List[tuple[torch.Tensor, torch.Tensor]], lr: float\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Runs one minibatch update\n",
    "\n",
    "        Key Equations of backpropagation\n",
    "\n",
    "        BP​1: δ^L =  ∇_a C ⊙ σ'(z^L)                        Get Error δ in last layer of network ∇_a C for quadratic cost 0.5(y(x) - a^L(x))² -> (a^L - y)\n",
    "        BP2: δ^l = ((w^{l+1})^T δ^{l+1}) ⊙ σ'(z^L)          Propagate Errors from last layer (BP1) through rest of network to all layers\n",
    "        BP3: ∂C/∂b^l_j = δ^l_j -> ∂C/∂b = δ                 Rate of change of cost wrp. to any bias\n",
    "        BP4: ∂C/∂w^l_jk = a^{l-1}_k δ^l_j -> a_in δ_out     Rate of change of cost wrp. to any weight\n",
    "\n",
    "        For all samples in minibatch\n",
    "            1. Get the errors and activations for all nodes\n",
    "            2. Calculate the gradients at the nodes and save them\n",
    "\n",
    "        Calculate average gradient at each node\n",
    "        3. Update weights and biases according to update rule\n",
    "            w_k' = w_k - lr * dC/dw_k\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8dc82b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle w_k \\rightarrow w_k' - \\eta \\frac{\\partial C}{\\partial w_k}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Math, display\n",
    "\n",
    "display(Math(r\"w_k \\rightarrow w_k' - \\eta \\frac{\\partial C}{\\partial w_k}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cc90eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    target_transform=Lambda(lambda y: F.one_hot(torch.tensor(y), num_classes=10)),\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    target_transform=Lambda(lambda y: F.one_hot(torch.tensor(y), num_classes=10)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982900a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b5e21d0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 28 is different from 784)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[140]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m net = Network([\u001b[32m784\u001b[39m, \u001b[32m20\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m10\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[137]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36mNetwork.train\u001b[39m\u001b[34m(self, train_data, epochs, batch_size, lr, test_data)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m test_data:\n\u001b[32m     74\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute the cost on the test set\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     test_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     test_results.append(test_result)\n\u001b[32m     77\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     78\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m Nr of correctly classified samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_test\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_result\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39mn_test\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     79\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[137]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mNetwork.evaluate\u001b[39m\u001b[34m(self, test_data)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, test_data: Dataset):\n\u001b[32m     32\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[33;03m    Nr of correctly classified test-samples\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     test_results = \u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mint\u001b[39m(x == y) \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m test_results)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[137]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, test_data: Dataset):\n\u001b[32m     32\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[33;03m    Nr of correctly classified test-samples\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     test_results = [(np.argmax(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m), y) \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m test_data]\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mint\u001b[39m(x == y) \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m test_results)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[137]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mNetwork.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Forward Pass through the Network\"\"\"\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m w, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.w, \u001b[38;5;28mself\u001b[39m.b):\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     z = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m + b\n\u001b[32m     28\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.sigmoid(z)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[31mValueError\u001b[39m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 28 is different from 784)"
     ]
    }
   ],
   "source": [
    "net = Network([784, 20, 10, 10])\n",
    "net.train(train_data, epochs=20, batch_size=30, lr=0.01, test_data=test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc17cf",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39204bfa",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc142fa6",
   "metadata": {},
   "source": [
    "Network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-network-from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
